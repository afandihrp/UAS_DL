{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning BERT for Natural Language Inference (MNLI)\n",
        "Natural Language Inference (NLI) is the task of determining whether a \"hypothesis\" is true (entailment), false (contradiction), or undetermined (neutral) given a \"premise\".\n",
        "\n",
        "## 1. Setup Environment and Installation\n",
        "We install the transformers and datasets libraries. Since MNLI is part of the GLUE benchmark, we will use the HuggingFace glue loader."
      ],
      "metadata": {
        "id": "N__L5I3hNU6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWtRsu4xLqiN",
        "outputId": "1df78f44-0e87-4234-8ac9-3e85223a0389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate evaluate scikit-learn -q\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and Explore the MNLI Dataset\n",
        "We load the dataset from the GLUE benchmark. Note that MNLI has two validation sets: matched (same domains as training) and mismatched (different domains)."
      ],
      "metadata": {
        "id": "ksu5f3d6NewY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNLI is part of the GLUE benchmark\n",
        "raw_datasets = load_dataset(\"glue\", \"mnli\")\n",
        "\n",
        "# Preview training data\n",
        "train_df = pd.DataFrame(raw_datasets['train']).head()\n",
        "print(\"MNLI Data Sample:\")\n",
        "print(train_df[['premise', 'hypothesis', 'label']])\n",
        "\n",
        "# Label mapping: 0 -> Entailment, 1 -> Neutral, 2 -> Contradiction\n",
        "labels = raw_datasets[\"train\"].features[\"label\"].names\n",
        "print(f\"\\nLabels: {labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8nfi5azMLqf",
        "outputId": "aa512f55-fbbc-4e6c-dbab-5c3af7da15fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNLI Data Sample:\n",
            "                                             premise  \\\n",
            "0  Conceptually cream skimming has two basic dime...   \n",
            "1  you know during the season and i guess at at y...   \n",
            "2  One of our number will carry out your instruct...   \n",
            "3  How do you know? All this is their information...   \n",
            "4  yeah i tell you what though if you go price so...   \n",
            "\n",
            "                                          hypothesis  label  \n",
            "0  Product and geography are what make cream skim...      1  \n",
            "1  You lose the things to the following level if ...      0  \n",
            "2  A member of my team will execute your orders w...      0  \n",
            "3                  This information belongs to them.      0  \n",
            "4           The tennis shoes have a range of prices.      1  \n",
            "\n",
            "Labels: ['entailment', 'neutral', 'contradiction']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Baseline Comparison (Traditional Machine Learning)\n",
        "For the baseline, we concatenate the premise and hypothesis with a separator and use TF-IDF with Logistic Regression."
      ],
      "metadata": {
        "id": "S1AknJ1wNnf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare text for baseline (concatenate premise and hypothesis)\n",
        "def prepare_baseline_text(dataset_split):\n",
        "    return [p + \" [SEP] \" + h for p, h in zip(dataset_split['premise'], dataset_split['hypothesis'])]\n",
        "\n",
        "train_texts = prepare_baseline_text(raw_datasets['train'].select(range(20000)))\n",
        "test_texts = prepare_baseline_text(raw_datasets['validation_matched'])\n",
        "\n",
        "y_train = raw_datasets['train'].select(range(20000))['label']\n",
        "y_test = raw_datasets['validation_matched']['label']\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "# Training Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Accuracy\n",
        "lr_preds = lr_model.predict(X_test)\n",
        "print(f\"Baseline (Logistic Regression) Accuracy: {accuracy_score(y_test, lr_preds):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiFCeoNvNwBu",
        "outputId": "e08445f6-6f60-4ebe-9756-351e32f14453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (Logistic Regression) Accuracy: 0.4177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. BERT Tokenization for Sentence Pairs\n",
        "Unlike single-sentence classification, BERT handles NLI by taking two inputs separated by a [SEP] token and using segment embeddings."
      ],
      "metadata": {
        "id": "pHeSa30_Nyw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Pass both premise and hypothesis to the tokenizer\n",
        "    return tokenizer(\n",
        "        examples[\"premise\"],\n",
        "        examples[\"hypothesis\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "908e76d834cc43be9a1b59b626d09ec8",
            "8d36a0ff74484542b0e946e3ffc5c9a3",
            "69be7947ad5a45bc992f4881193d4540",
            "343211723a7b4c4fa37284a699a27a37",
            "eab0c1fab4344180ac89b0c7d7caccb9",
            "250569920924465aaedc4c9b2cc15f30",
            "17a8c931ab0a4edc846cfd2cf86e892e",
            "e9d2b0198e7340fda21de060dad56af8",
            "12e9ac1dd9a8496dadc3c5e0b689f2ef",
            "6b606f66d4a84637b7a34e03838d24da",
            "80ea785e037c4655a48fbb5812f2ff9f",
            "f411b0ccd3ef4c8397f2f7d51274a75e",
            "9695e044c40246bcaa69ead1c46b6d46",
            "93dddb0134fe403c8019e0a44f431e3e",
            "8471aa17e0604b5694db7f56fb68a2eb",
            "b6d44ee831ff43c7bce3cf84bb7392bf",
            "234fd843495740d1ad6fbd1ea3e9b724",
            "8f7679e889f6470388c2043d512e1b8d",
            "38791cb821d44f1a81d60dd0920c0fe1",
            "8a0f5f219cd144f0b46d803399332746",
            "be1030bd78cd4a47825c21a7ae08b3e8",
            "d74955be3bef475abad161050b3cd601",
            "6e1b78a2e59c4f0c8618811eabd0a383",
            "4c3c4d6e935f49edbddd54e26e07531a",
            "0430f2a20479437fb1642edf092435d3",
            "640ee14f583a4142b7630463ca80ec12",
            "6372b66990624a3a9ec69f9b8c012657",
            "3ff06ece6d0e4ab486ec848aaf0b55ba",
            "a6c12ba1fa31407cb93f5007b93b54af",
            "97491a0dc27a458f9fc172b5e3c7e214",
            "c340d1a23e4e47488d673f5f95039fa6",
            "0e049621f2654cb68fdec7954e154eeb",
            "95d07e60a5f14557b1b68c49a5c77688",
            "81a1490ba3d24a8ab820a1418b17eeae",
            "04e17f07da3b4cb99065b67a864ef381",
            "afbfe444fc494e48ba6b58f8faac26f8",
            "63c4f3e69e834bf9811eccc1987bb886",
            "234480c8ec9c4af1b28107092c4024b3",
            "2da023bfe8a74ddca304dc2d77667321",
            "4437c59f64d9435eb4d5a8c34dee591b",
            "f2d43d4d9a7648baba665d6ad7b0e349",
            "fbdb46533d0b45a99ad37d92e2fa048c",
            "41e1ce17877b4f289395ba5e296844ad",
            "627055a3fc994805a5143686a3422acf",
            "60b44a0c88c64b63ac18f6393e4cffb4",
            "ff4bc3f4228e422e855939db7bbe799b",
            "fcb1a77d16634d3898cbd4801794de14",
            "fb5c5fd5980f4ff3be140a015aaa93d0",
            "efc2d23c62f5451fbb25ad6973bbd834",
            "30962909e0f7432bb1604afa8e061ab9",
            "c955f12c3f7944109409e997dd6f46b2",
            "ae05e5833b5747e58e9238b514675836",
            "b41ef8a912f047249bcb868e3c4b649f",
            "5d6db38b4fdc48449748810aea06572c",
            "1749689f096c416a82e83e36e5d5ee5f",
            "f0b320cc67924a1fb5ab628a9671dea9",
            "b76ea2e60cfe404eb484182b4ed7d489",
            "e0ae5841d522452eaa9134db42d76a0b",
            "c69ff681ecd9483cbda1bf6eeb868c3e",
            "28fe00be405944478b2fd9a6610a5683",
            "2aa637f7745b45c49db909e661c87d86",
            "6cb2e1078b034b8382e07f587a440556",
            "2063b39ac9aa4efabcb7f83915f554fd",
            "13215125af7844e3acc89473f54b2dd0",
            "85a36e1aa523452894f76bcba93d72eb",
            "d317b3a6f78b44faa1d9e0a346f7cc00",
            "738f0f1fca244bd7af10ddf6dcb9e660",
            "998a73345d6746ceb53601b6738f6afd",
            "d177bd499cd743ccbc1fc0a5140b2be2",
            "52bb556624224fb39fc6640b653bc43b",
            "15abbfbc209c41af8844f0a581bea47c",
            "7878ad3077bb4a5c825d86dc66c35230",
            "685a07c86c374366b7519c851ce1c00e",
            "99e48ea4af174cebbb657642e816ff87",
            "8481d8312a604f18ad443b41745bcd5c",
            "a3278a24c12048e3983908ae073096ad",
            "3a7bae3bbac748668ef42ff5401e693b",
            "db35fe4a629e496b9ad205877d4e44b7",
            "64188cefcbee433f9bc0fb86a76e9ba4",
            "350c5348521a4d7b9b4b7712b2618471",
            "37ac722d6b354fc68ca1ad82ad9acd7b",
            "410f11e161f74fff9cc8974b35d72272",
            "e5738c86dfe0452caa96e3abe5cfa78a",
            "02d4ab62bf374609975105c2815dd7bf",
            "e66d8cb3629240faa4ec8e28edd4353c",
            "f2d38d2d631e4d51ae1ea3ede8a38bd4",
            "044c2faca8ad484db1c6a1a1a67b2c93",
            "8843a7a914c74627abf93ac06999d365",
            "d6e41a8c2eb9473f9b6a2b97366a5893",
            "f14a91f64911484899f25116c3952364",
            "8baedab2e11e414f842c4b4d00f29339",
            "923e2182a6074bd295e0c4f5245d7cc9",
            "dcceb80393be4a8b9a2eb870d285def0",
            "130394fda2844035b2ffcb8caadc0033",
            "9d54e5ba6e604d42a49072f77ecfb85f",
            "cb4207f8eece40679a8148e8267fd637",
            "aff4434d68354e0885d3c84a02d9e202",
            "09ea626b43f248248b8aba99b21157de",
            "8f7f1cc45a734cacba7cb5105704c4ef"
          ]
        },
        "id": "HE_9rwOnN1XF",
        "outputId": "a693bffb-4186-4dca-f021-8214bc10a781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "908e76d834cc43be9a1b59b626d09ec8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f411b0ccd3ef4c8397f2f7d51274a75e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e1b78a2e59c4f0c8618811eabd0a383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81a1490ba3d24a8ab820a1418b17eeae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b44a0c88c64b63ac18f6393e4cffb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0b320cc67924a1fb5ab628a9671dea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "738f0f1fca244bd7af10ddf6dcb9e660"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db35fe4a629e496b9ad205877d4e44b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6e41a8c2eb9473f9b6a2b97366a5893"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Configuration\n",
        "We load bert-base-uncased with 3 output labels for Entailment, Neutral, and Contradiction."
      ],
      "metadata": {
        "id": "rIW8B3VBN4no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "model.to(device)\n",
        "\n",
        "import evaluate\n",
        "metric = evaluate.load(\"glue\", \"mnli\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "73604227291c49e2b624efb793407789",
            "c8a4e024b0c74f1e8d97b9431c260f54",
            "c63a27fbc7ac4ba2bb1c04a0bfc5a573",
            "1d1190c837504032be399d3e5a593986",
            "f3810af4cee5450e901413ecafe975fd",
            "bb29cc8d0fd449079bbc69e02cef3839",
            "84be5a3978094226aba5b6b223d444cb",
            "1c84ce6a480a4ce38703145eb8dfd00f",
            "fc3d9910b9d44d279239821ae009da2b",
            "261fbdc75e2446e2b4f8ff6763537baf",
            "89a7c4046a2d4c04af06913e1674c965",
            "cd21433df1ef46a080aceeac4639739e",
            "55b0bdfca70f47fd9c7dfbf575c57f6d",
            "b23aaabd3fd640f8a78d4871d9c57f2b",
            "9721c6292bcd40b1b91262f3bafdeaae",
            "ac01a6de45014b069de23b6230b4b6a5",
            "96ae7aa891bc4467b201749fa11a5c97",
            "c726abc56df14a20ba2fc2302a72397e",
            "b3abcfa3ce6b4dadba0bc3ebe08911f1",
            "4d4ed31fc45c4599ababea8388aded54",
            "b8f7e369de634824a8923f03e17314bb",
            "0e2c43f6955e4c0199929e673c33715c"
          ]
        },
        "id": "kSnynzTPN6mr",
        "outputId": "4372999b-0cc8-4477-c7fd-cc13698ac396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73604227291c49e2b624efb793407789"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd21433df1ef46a080aceeac4639739e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Fine-Tuning BERT for NLI\n",
        "We use the Trainer API. Because MNLI is very large (~392k rows), we will train on a smaller subset (15,000 samples) for this assignment task."
      ],
      "metadata": {
        "id": "XpSYpPsfN9B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"finetuning-bert-nli\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Calculate the fraction for 15000 samples to maintain stratification\n",
        "num_total_train_samples = len(tokenized_datasets[\"train\"])\n",
        "target_train_size = 500\n",
        "train_split_fraction = target_train_size / num_total_train_samples\n",
        "\n",
        "# Create a stratified sample\n",
        "# The train_test_split method on a Dataset returns a DatasetDict with 'train' and 'test' keys\n",
        "stratified_split = tokenized_datasets[\"train\"].train_test_split(\n",
        "    train_size=train_split_fraction, # This will be the smaller training set\n",
        "    stratify_by_column=\"label\",\n",
        "    seed=42 # for reproducibility\n",
        ")\n",
        "\n",
        "# Use the 'train' part of the stratified split as the new training dataset\n",
        "stratified_train_dataset = stratified_split[\"train\"]\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=stratified_train_dataset,\n",
        "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "KDrLdvKpOGLf",
        "outputId": "9ecf6198-a27e-4e5d-8a93-f34e6b7aecb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 2:23:20, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.891076</td>\n",
              "      <td>0.599796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.889205</td>\n",
              "      <td>0.620173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=64, training_loss=0.6409909129142761, metrics={'train_runtime': 8620.5205, 'train_samples_per_second': 0.116, 'train_steps_per_second': 0.007, 'total_flos': 65778354432000.0, 'train_loss': 0.6409909129142761, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Final Evaluation and Saving\n",
        "We evaluate on the validation_matched set and save the model to fulfill the GitHub submission requirement."
      ],
      "metadata": {
        "id": "WDDFlcjKOI5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate BERT\n",
        "results = trainer.evaluate()\n",
        "print(f\"Final BERT Accuracy on MNLI Matched: {results['eval_accuracy']:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./finetuning-bert-nli\")\n",
        "tokenizer.save_pretrained(\"./finetuning-bert-nli\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4tmDnoScOMAA",
        "outputId": "bce06afd-57bc-4291-c44a-1c970846f3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1227' max='1227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1227/1227 1:01:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final BERT Accuracy on MNLI Matched: 0.6202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuning-bert-nli/tokenizer_config.json',\n",
              " './finetuning-bert-nli/special_tokens_map.json',\n",
              " './finetuning-bert-nli/vocab.txt',\n",
              " './finetuning-bert-nli/added_tokens.json',\n",
              " './finetuning-bert-nli/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Inference (Prediction)\n",
        "Test the model with custom premise-hypothesis pairs."
      ],
      "metadata": {
        "id": "L-y0k2L3OO1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nli_pipeline = pipeline(\"text-classification\", model=\"./finetuning-bert-nli\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Example: Entailment\n",
        "p = \"A soccer game with multiple players owns the field.\"\n",
        "h = \"Some people are playing a sport.\"\n",
        "\n",
        "# Note: pipeline for NLI usually takes a single string or formatted input\n",
        "# For BERT NLI, we often manually format or use the model directly\n",
        "def predict_nli(premise, hypothesis):\n",
        "    inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    prediction = torch.argmax(logits, dim=-1).item()\n",
        "    return labels[prediction]\n",
        "\n",
        "print(f\"Premise: {p}\")\n",
        "print(f\"Hypothesis: {h}\")\n",
        "print(f\"Prediction: {predict_nli(p, h)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ5ucApdORhX",
        "outputId": "e028a2c3-75ea-4c4a-b767-f12d7d0ed20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Premise: A soccer game with multiple players owns the field.\n",
            "Hypothesis: Some people are playing a sport.\n",
            "Prediction: neutral\n"
          ]
        }
      ]
    }
  ]
}
